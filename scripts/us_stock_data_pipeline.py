#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
US Stock Data Pipeline - CSV + Live (yfinance + Finnhub)
--------------------------------------------------------
æ–°å¢ï¼š
  --yesterday_only   åªè¾“å‡ºæ˜¨æ—¥ä¸€è¡Œï¼ˆä»æ‹‰è¶³å†å²ç”¨äº MA/RSI è®¡ç®—ï¼‰

å†å²æ‰¹å¤„ç†ï¼š
  python us_stock_data_pipeline.py --tickers OKLO LEU --days 90 --intraday_days 5
åªè¾“å‡ºæ˜¨æ—¥ï¼ˆæ¨è days â‰¥ 60 ä¿è¯æŒ‡æ ‡å……åˆ†ï¼‰ï¼š
  python us_stock_data_pipeline.py --tickers OKLO LEU --days 60 --intraday_days 5 --yesterday_only
å®æ—¶ï¼ˆéœ€ FINNHUB_API_KEYï¼‰ï¼š
  python us_stock_data_pipeline.py --tickers OKLO LEU --live 1m
è°ƒè¯•ï¼š
  python us_stock_data_pipeline.py --tickers AAPL --days 5 --intraday_days 1 --debug

ä¾èµ–ï¼š
  pip install yfinance pandas numpy requests finnhub-python
"""
import argparse
import datetime as dt
import os
import sys
import time
from typing import List, Optional, Tuple
import numpy as np
import pandas as pd

# -------------------- yfinance --------------------
try:
    import yfinance as yf
except Exception:
    print("[ERROR] è¯·å…ˆå®‰è£… yfinanceï¼špip install yfinance", file=sys.stderr)
    sys.exit(1)

# -------------------- å·¥å…·ï¼šåˆ—åå½’ä¸€åŒ– --------------------
def _norm_key(s: str) -> str:
    return "".join(ch for ch in s.lower() if ch.isalnum())

def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    if isinstance(out.columns, pd.MultiIndex):
        out.columns = [" ".join([str(x) for x in tup if x is not None]).strip() for tup in out.columns]
    else:
        out.columns = [str(c) for c in out.columns]
    return out

def pick_column(cols: List[str], *candidates: str) -> Optional[str]:
    norm_map = {_norm_key(c): c for c in cols}
    for cand in candidates:  # ç²¾ç¡®
        k = _norm_key(cand)
        if k in norm_map:
            return norm_map[k]
    for cand in candidates:  # å®½æ¾
        k = _norm_key(cand)
        for c in cols:
            nk = _norm_key(c)
            if nk.startswith(k) or k in nk:
                return c
    return None

def normalize_ohlcv(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        return pd.DataFrame()
    df = normalize_columns(df)
    cols = list(df.columns)

    open_col  = pick_column(cols, "Open")
    high_col  = pick_column(cols, "High")
    low_col   = pick_column(cols, "Low")
    close_col = pick_column(cols, "Close", "Adj Close", "AdjClose")
    vol_col   = pick_column(cols, "Volume", "Vol", "TotalVolume")
    adj_col   = pick_column(cols, "Adj Close", "AdjClose")

    out = pd.DataFrame(index=df.index)
    if open_col:  out["Open"]   = pd.to_numeric(df[open_col], errors="coerce")
    if high_col:  out["High"]   = pd.to_numeric(df[high_col], errors="coerce")
    if low_col:   out["Low"]    = pd.to_numeric(df[low_col], errors="coerce")
    if vol_col:   out["Volume"] = pd.to_numeric(df[vol_col], errors="coerce")

    if close_col:
        out["Close"] = pd.to_numeric(df[close_col], errors="coerce")
    elif adj_col:
        out["Close"] = pd.to_numeric(df[adj_col], errors="coerce")

    if adj_col:
        out["AdjClose"] = pd.to_numeric(df[adj_col], errors="coerce")

    return out.dropna(how="all", axis=1)

# -------------------- æŒ‡æ ‡ --------------------
def rsi(series: pd.Series, period: int = 14) -> pd.Series:
    series = pd.to_numeric(series, errors="coerce")
    delta = series.diff()
    gain = delta.clip(lower=0)
    loss = -delta.clip(upper=0)
    avg_gain = gain.ewm(alpha=1/period, min_periods=period, adjust=False).mean()
    avg_loss = loss.ewm(alpha=1/period, min_periods=period, adjust=False).mean()
    rs = avg_gain / avg_loss.replace(0, np.nan)
    return (100 - (100 / (1 + rs))).ffill()

def moving_averages(close: pd.Series, windows=(5, 10, 20, 30, 60)) -> pd.DataFrame:
    close = pd.to_numeric(close, errors="coerce")
    out = pd.DataFrame(index=close.index)
    for w in windows:
        out[f"MA{w}"] = close.rolling(w).mean()
    return out

def vwap(df: pd.DataFrame) -> pd.Series:
    tp = (df["High"] + df["Low"] + df["Close"]) / 3
    cum_tp_vol = (tp * df["Volume"]).cumsum()
    cum_vol = df["Volume"].cumsum().replace(0, np.nan)
    return (cum_tp_vol / cum_vol).ffill()

def first_n_minutes_volume(intra: pd.DataFrame, n_minutes: int = 30) -> float:
    if intra.empty:
        return np.nan
    if intra.index.tz is not None:
        intra_local = intra.copy()
        intra_local.index = intra_local.index.tz_convert("US/Eastern")
    else:
        intra_local = intra.tz_localize("UTC").tz_convert("US/Eastern")
    last_date = intra_local.index[-1].date()
    start = pd.Timestamp.combine(pd.Timestamp(last_date), pd.Timestamp("09:30").time()).tz_localize("US/Eastern")
    end = start + pd.Timedelta(minutes=n_minutes)
    window = intra_local[(intra_local.index >= start) & (intra_local.index < end)]
    return float(window["Volume"].sum()) if "Volume" in window.columns else np.nan

def prev_day_pivots_safe(daily: pd.DataFrame) -> Tuple[float, float, float]:
    if len(daily) < 2:
        return np.nan, np.nan, np.nan
    prev = daily.iloc[-2]
    H = pd.to_numeric(prev.get("High", np.nan), errors="coerce")
    L = pd.to_numeric(prev.get("Low", np.nan), errors="coerce")
    C = pd.to_numeric(prev.get("Close", np.nan), errors="coerce")
    if any(pd.isna(v) for v in (H, L, C)):
        return np.nan, np.nan, np.nan
    p = (H + L + C) / 3.0
    r1 = 2 * p - L
    s1 = 2 * p - H
    return p, r1, s1

# -------------------- æ•°æ®è·å–ï¼ˆyfinanceï¼‰ --------------------
def fetch_daily_yf(symbol: str, start: str, end: str, debug: bool=False) -> pd.DataFrame:
    raw = yf.download(symbol, start=start, end=end, progress=False, interval="1d",
                      auto_adjust=False, group_by="column")
    if raw is None or raw.empty:
        raise RuntimeError(f"yfinance è¿”å›ç©ºæ—¥çº¿æ•°æ®ï¼ˆ{symbol}ï¼‰")
    if debug:
        print(f"[DEBUG] {symbol} daily raw cols:", list(normalize_columns(raw).columns))
    df = normalize_ohlcv(raw)
    if df.empty or "Close" not in df.columns:
        raise RuntimeError(f"{symbol} æ—¥çº¿ç¼ºå°‘ Closeï¼›åŸå§‹åˆ—: {list(normalize_columns(raw).columns)}")
    return df

def fetch_intraday_yf(symbol: str, intraday_days: int = 10, interval: str = "5m", debug: bool=False) -> pd.DataFrame:
    intervals_try = [interval, "15m"] if interval != "15m" else ["15m"]
    last_err = None
    for iv in intervals_try:
        for attempt in range(3):
            try:
                raw = yf.download(symbol, period=f"{intraday_days}d", interval=iv,
                                  progress=False, auto_adjust=False, prepost=False, group_by="column")
                if raw is not None and not raw.empty:
                    if debug:
                        print(f"[DEBUG] {symbol} {iv} raw cols:", list(normalize_columns(raw).columns))
                    df = normalize_ohlcv(raw)
                    if df.empty or "Close" not in df.columns:
                        last_err = RuntimeError(f"{symbol} {iv} ç¼ºå°‘ Closeï¼›åŸå§‹åˆ—: {list(normalize_columns(raw).columns)}")
                    else:
                        df.attrs["interval_used"] = iv
                        return df
                else:
                    last_err = RuntimeError(f"{symbol} {iv} è¿”å›ç©ºæ•°æ®")
            except Exception as e:
                last_err = e
            time.sleep(1 + attempt)
    raise RuntimeError(f"æ— æ³•è·å– {symbol} çš„åˆ†é’Ÿæ•°æ®ï¼ˆå·²å°è¯• 5m/15mï¼‰ï¼š{last_err}")

# -------------------- æ„å»ºè¡¨ --------------------
def build_daily_metrics(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out["Close"] = pd.to_numeric(out["Close"], errors="coerce")
    mas = moving_averages(out["Close"], windows=(5,10,20,30,60))
    out = pd.concat([out, mas], axis=1)
    out["RSI14"] = rsi(out["Close"], 14)
    return out

def build_intraday_metrics(df_intra: pd.DataFrame) -> pd.DataFrame:
    out = df_intra.copy()
    if all(c in out.columns for c in ["High", "Low", "Close", "Volume"]):
        out["VWAP"] = vwap(out)
    else:
        out["VWAP"] = np.nan
    return out

def summarize_signals(symbol: str, daily_for_signal: pd.DataFrame, intra: Optional[pd.DataFrame]) -> pd.DataFrame:
    valid = daily_for_signal.copy()
    valid["Close"] = pd.to_numeric(valid["Close"], errors="coerce")
    valid = valid.dropna(subset=["Close"])
    if valid.empty:
        raise RuntimeError(f"{symbol}: æ²¡æœ‰æœ‰æ•ˆçš„ Close å€¼å¯ç”¨äºç”Ÿæˆ Signals")

    last = valid.iloc[-1]

    def as_float(x):
        x = pd.to_numeric(x, errors="coerce")
        return float(x) if pd.notna(x) else np.nan

    ma_vals = {f"MA{w}": as_float(last.get(f"MA{w}", np.nan)) for w in (5,10,20,30,60)}
    rsi14 = as_float(last.get("RSI14", np.nan))
    last_close = as_float(last.get("Close", np.nan))

    p, r1, s1 = prev_day_pivots_safe(valid)

    first30 = np.nan
    if intra is not None and not intra.empty and "Volume" in intra.columns:
        try:
            first30 = first_n_minutes_volume(intra, 30)
        except Exception:
            first30 = np.nan

    avg5_vol = np.nan
    if "Volume" in valid.columns:
        vol5 = pd.to_numeric(valid["Volume"], errors="coerce").tail(5)
        if not vol5.dropna().empty:
            avg5_vol = float(vol5.mean())

    ratio = np.nan
    if pd.notna(first30) and pd.notna(avg5_vol) and avg5_vol != 0:
        ratio = float(first30 / avg5_vol)

    row = {
        "Symbol": symbol,
        "LastClose": last_close,
        "MA5": ma_vals["MA5"], "MA10": ma_vals["MA10"], "MA20": ma_vals["MA20"],
        "MA30": ma_vals["MA30"], "MA60": ma_vals["MA60"],
        "RSI14": rsi14,
        "Pivot_P": p, "Pivot_R1": r1, "Pivot_S1": s1,
        "First30mVol_today": float(first30) if pd.notna(first30) else np.nan,
        "Avg5D_Volume": float(avg5_vol) if pd.notna(avg5_vol) else np.nan,
        "First30mVol_vs_5D": ratio,
    }
    return pd.DataFrame([row])

# -------------------- ä¸»ç®¡é“ --------------------
def run_pipeline(tickers: List[str], days: int, intraday_days: int, debug: bool=False, yesterday_only: bool=False):
    # ä¸ºäº†ä¿è¯æŒ‡æ ‡è®¡ç®—ï¼Œå»ºè®® days å–è¾ƒå¤§å€¼ï¼›ä½†æŒ‰ç”¨æˆ·æŒ‡å®šæ‰§è¡Œ
    start_date = (dt.date.today() - dt.timedelta(days=days)).isoformat()
    end_date = (dt.date.today() + dt.timedelta(days=1)).isoformat()
    all_signals = []
    logs = []

    for sym in tickers:
        print(f"\n=== {sym} ===")
        # æ—¥çº¿
        try:
            daily_raw = fetch_daily_yf(sym, start_date, end_date, debug=debug)
            daily_full = build_daily_metrics(daily_raw).copy()  # å®Œæ•´å†å²ï¼ˆç”¨äºç”Ÿæˆ Signalsï¼‰
            daily_full = daily_full.dropna(subset=["Close"])

            # é€‰æ‹©æœ€ç»ˆä¿å­˜çš„æ—¥çº¿ï¼ˆæ˜¯å¦åªç•™æ˜¨æ—¥ï¼‰
            daily_to_save = daily_full
            if yesterday_only and not daily_full.empty:
                y = (dt.date.today() - dt.timedelta(days=1)).isoformat()
                d_y = daily_full[daily_full.index.strftime("%Y-%m-%d") == y]
                daily_to_save = d_y if not d_y.empty else daily_full.tail(1)

            # åˆ—é¡ºåº
            cols_order = [c for c in ["Open","High","Low","Close","AdjClose","Volume",
                                      "MA5","MA10","MA20","MA30","MA60","RSI14"] if c in daily_to_save.columns]
            daily_to_save = daily_to_save[cols_order]
            daily_to_save.to_csv(f"{sym}_Daily.csv", index=True)
            tag = "ï¼ˆä»…æ˜¨æ—¥ï¼‰" if yesterday_only else "ï¼ˆå« MA/RSIï¼‰"
            print(f"âœ” å·²ä¿å­˜ {sym}_Daily.csv {tag}")
        except Exception as e:
            msg = f"{sym} daily é”™è¯¯: {e}"
            logs.append(msg); print("âš ", msg)
            continue

        # åˆ†é’Ÿ
        intra = None
        try:
            intra = fetch_intraday_yf(sym, intraday_days, "5m", debug=debug)
            interval_used = intra.attrs.get("interval_used", "5m")
            intra = build_intraday_metrics(intra)
            out_name = f"{sym}_{interval_used}.csv" if interval_used != "5m" else f"{sym}_5m.csv"
            intra.to_csv(out_name, index=True)
            print(f"âœ” å·²ä¿å­˜ {out_name}")
        except Exception as e:
            msg = f"{sym} intraday é”™è¯¯: {e}"
            logs.append(msg); print("âš ", msg)

        # Signalsï¼ˆå§‹ç»ˆç”¨å®Œæ•´å†å² daily_full ç”Ÿæˆï¼Œé¿å…åªç•™æ˜¨æ—¥æ—¶ä¸¢å¤±ä¸Šä¸‹æ–‡ï¼‰
        try:
            sig = summarize_signals(sym, daily_full, intra)
            sig.to_csv(f"{sym}_Signals.csv", index=False)
            all_signals.append(sig)
            print(f"âœ” å·²ä¿å­˜ {sym}_Signals.csv")
        except Exception as e:
            msg = f"{sym} signals é”™è¯¯: {e}"
            logs.append(msg); print("âš ", msg)

    if all_signals:
        combined = pd.concat(all_signals, ignore_index=True)
        combined.to_csv("All_Signals.csv", index=False)
        print("âœ” å·²ä¿å­˜ All_Signals.csv")

    if logs:
        with open("LOGS.txt", "w", encoding="utf-8") as f:
            f.write("\n".join(logs))
        print("âš  ä¸€äº›æ ‡çš„å‡ºç°é”™è¯¯ï¼Œè¯¦æƒ…è§ LOGS.txt")

# -------------------- Finnhub å®æ—¶æ¨¡å¼ --------------------
def parse_live_interval(s: str) -> int:
    s = s.strip().lower()
    if s.endswith("s"):
        return int(s[:-1])
    if s.endswith("m"):
        return int(s[:-1]) * 60
    raise ValueError("live ä»…æ”¯æŒ '10s' æˆ– '1m' æ ¼å¼")

def fetch_live_prices(symbols: List[str], interval_sec: int):
    try:
        import finnhub
    except Exception:
        print("[ERROR] å®æ—¶æ¨¡å¼éœ€è¦ finnhub-pythonï¼špip install finnhub-python", file=sys.stderr)
        sys.exit(1)

    api_key = os.getenv("FINNHUB_API_KEY")
    if not api_key:
        raise RuntimeError("è¯·å…ˆè®¾ç½® FINNHUB_API_KEY ç¯å¢ƒå˜é‡")

    client = finnhub.Client(api_key=api_key)
    fname = "Live_" + "_".join(symbols) + ".csv"
    if not os.path.exists(fname):
        pd.DataFrame(columns=["Timestamp", "Symbol", "Price", "Change", "PrevClose"])\
          .to_csv(fname, index=False)

    print(f"ğŸš€ å¼€å§‹å®æ—¶ç›‘æ§: {symbols}ï¼ˆé—´éš” {interval_sec}sï¼‰")
    while True:
        now = dt.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        rows = []
        for sym in symbols:
            try:
                q = client.quote(sym)
                price = q.get("c")
                prev_close = q.get("pc")
                change = (price - prev_close) / prev_close * 100 if (price is not None and prev_close) else np.nan
                print(f"{now} | {sym:<6} {price!s:>8} | Î” {change:+6.2f}%")
                rows.append([now, sym, price, change, prev_close])
            except Exception as e:
                print(f"âš  {sym} å®æ—¶æŠ“å–å¤±è´¥: {e}")
        if rows:
            pd.DataFrame(rows, columns=["Timestamp","Symbol","Price","Change","PrevClose"])\
              .to_csv(fname, mode="a", header=False, index=False)
        time.sleep(interval_sec)

# -------------------- CLI --------------------
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--tickers", nargs="+", required=True, help="è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚ OKLO LEU AAPL")
    parser.add_argument("--days", type=int, default=90, help="æ—¥çº¿å¤©æ•°ï¼ˆé»˜è®¤90ï¼‰")
    parser.add_argument("--intraday_days", type=int, default=10, help="åˆ†é’Ÿæ•°æ®å¤©æ•°ï¼ˆé»˜è®¤10ï¼Œyfinance 5m é€šå¸¸â‰¤60å¤©ï¼‰")
    parser.add_argument("--yesterday_only", action="store_true", help="åªè¾“å‡ºæ˜¨æ—¥æ•°æ®ï¼ˆå«å®Œæ•´æŒ‡æ ‡ï¼‰")
    parser.add_argument("--live", type=str, help="å®æ—¶ç›‘æ§é—´éš”ï¼Œå¦‚ '10s' æˆ– '1m'")
    parser.add_argument("--debug", action="store_true", help="æ‰“å°åŸå§‹åˆ—å/è°ƒè¯•ä¿¡æ¯")
    args = parser.parse_args()

    # å®æ—¶æ¨¡å¼
    if args.live:
        interval_sec = parse_live_interval(args.live)
        fetch_live_prices(args.tickers, interval_sec)
        sys.exit(0)

    # å†å²æ‰¹å¤„ç†
    run_pipeline(args.tickers, args.days, args.intraday_days, debug=args.debug, yesterday_only=args.yesterday_only)
